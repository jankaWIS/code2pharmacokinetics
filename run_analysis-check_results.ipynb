{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check analysis of depos visually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Measures:\n",
    "1) Total signal in the field of view of the corresponding mice/ organ (sum of all pixels). This value was regarded as total signal of mice (IEX+IN)\n",
    "\n",
    "2) Number of pixels with values above predetermined threshold (hodnota). This value was regarded as size of depot in mice (SEX+IN)\n",
    "\n",
    "3) K10[OG1]  index of depots. In this parameter, mean value of top 10% most intensive pixels in the FOV are divided by the mean of pixels above threshold (hodnota). This value was used as an indicator of distribution width of the depot.\n",
    "\n",
    "4) Fractal analysis of the shape of shape of the depot (pixels with values above predetermined threshold hodnota). This value was used as an indicator of distribution width of the depot.\n",
    "\n",
    "\n",
    "----\n",
    "## NOTES\n",
    "1. IF date is missing -- take it from the name\n",
    "\n",
    "2. IF shape is 2048x2048, interpolate it to 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jupyter nbconvert run_analysis-check_results.ipynb --no-input --to html\n",
    "\n",
    "import h5py\n",
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time as timer # because I use time all over as a variable\n",
    "\n",
    "# Importing module for functions\n",
    "functions_modul =  \"./functions\"\n",
    "sys.path.insert(0, functions_modul)\n",
    "\n",
    "from load_h5_into_np import load_h5_into_np\n",
    "\n",
    "# load function for analysis of the images\n",
    "from process_signal import get_total_signal_and_area\n",
    "\n",
    "\n",
    "# start the timer\n",
    "start = timer.time()\n",
    "\n",
    "# define path\n",
    "all_files_path = \"./frg\"\n",
    "mouse_slots_path = \"./mice_idx\"\n",
    "current_path = \"./\"\n",
    "\n",
    "# load correction matrix\n",
    "# correction_matrix_slots_mice_all = np.load(\"correction_matrix_slots_mice_all.npy\")\n",
    "correction_matrix_slots_mice_all = np.load(os.path.join(current_path,\"correction_matrix_slots_mice_all.npy\"))\n",
    "\n",
    "# load example files\n",
    "all_files = os.listdir(all_files_path)\n",
    "# remove control files -- they are accounted for in the correlation matrix\n",
    "test_files = [x for x in all_files if \"kontrola\" not in x]\n",
    "\n",
    "# Load positions of mice from bcg check (done half-manually in analyse_bcg-manual_check.ipynb)\n",
    "\n",
    "df = pd.read_csv(os.path.join(mouse_slots_path, 'good_mice_idx.csv'))\n",
    "bad_slots = pd.read_excel(os.path.join(mouse_slots_path, 'remove.xlsx'))\n",
    "bad_slots.rename(columns={\"Full reject\":\"unique_labels\"}, inplace=True)\n",
    "\n",
    "# load the time date info\n",
    "df_date_info = pd.read_csv(os.path.join(current_path,'./GetDates-FRG.csv'))\n",
    "df_date_info[\"Datetime\"] = pd.to_datetime(df_date_info['Date'] + ' ' + df_date_info['Time'])\n",
    "df_date_info[\"strip_name\"] = df_date_info.Filename.str.split(\"MWL\").str[0]\n",
    "# without the time\n",
    "df_date_info[\"id_name\"] = df_date_info.Filename.str.split(\"_\").str[:-4].str.join('_')\n",
    "\n",
    "# read dict of known mismatch names\n",
    "df_rename_dict = pd.read_csv(os.path.join(current_path,'rename_dict.csv'))\n",
    "\n",
    "# run the analysis\n",
    "off = 70\n",
    "background = 25\n",
    "thr = 200  # threshold for depo\n",
    "signal_arr = []\n",
    "missing_date = []\n",
    "missing_date2 = []\n",
    "missing_bcg = []\n",
    "wrong_shape = []\n",
    "reduced_size = (1024, 1024)  # to which size we want to convert the bigger ones\n",
    "plot_slots = True\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"name\",\n",
    "        \"mouse_name\",  # for being able to follow one mouse over time\n",
    "        \"slot\",\n",
    "        \"type\",\n",
    "        \"viewpoint\", # which part of the mouse was captured\n",
    "        \"area\",\n",
    "        \"intensity_mean\",\n",
    "        \"intensity_mean_depo\",\n",
    "        \"intensity_max\",\n",
    "        \"intensity_median\",\n",
    "        \"intensity_median_depo\",\n",
    "        \"full_signal_mean\",  # done on original matrix without thr\n",
    "        \"full_signal_sum\",\n",
    "        \"total_signal\",\n",
    "        \"total_signal_depo\",\n",
    "        \"k10\",\n",
    "        \"date\",\n",
    "        \"time\",\n",
    "        \"datetime\",\n",
    "        \"time_zero\",\n",
    "        \"matrix_shape\"\n",
    "    ])\n",
    "\n",
    "for file in test_files:\n",
    "    df_tmp = None\n",
    "    slots = None\n",
    "    tmp_arr = None\n",
    "    zero_time = False\n",
    "    unique_label = None\n",
    "    viewpoint = None    \n",
    "\n",
    "    # take the name without the img and the end part\n",
    "    frg_name = '_'.join((file.split('MWL')[0]).split('_')[1:])\n",
    "\n",
    "    # check if it needs to be renamed (known mismatches)\n",
    "    if frg_name in df_rename_dict[\"frg_name\"].values:\n",
    "        bcg_name = df_rename_dict.loc[df_rename_dict[\"frg_name\"] == frg_name, \"bcg_name\"].values[0]\n",
    "    else:\n",
    "        bcg_name = frg_name\n",
    "\n",
    "    # find the relevant date-time result\n",
    "    if df_date_info[df_date_info.Filename.str.contains(frg_name)].Date.values.size == 0:\n",
    "        # either put nothing there\n",
    "        #         date = np.nan\n",
    "        #         time = np.nan\n",
    "        #         datetime = np.nan\n",
    "        # or get it from the name\n",
    "        date = '/'.join(\n",
    "            frg_name.split('_')[-2].split('-')[1::] + [frg_name.split('_')[-2].split('-')[0]])  # mm/dd/yyyy\n",
    "        time = frg_name.split('_')[-1].replace('-', ':')[:-1]\n",
    "        datetime = pd.to_datetime(date + ' ' + time)\n",
    "\n",
    "        # save the name to check later\n",
    "        missing_date.append(frg_name)\n",
    "        missing_date2.append(file)\n",
    "        print(f\"\\nThe following name was not found in the date_csv.\\n{frg_name}.\\n\\n\")\n",
    "    else:\n",
    "        date = df_date_info[df_date_info.Filename.str.contains(frg_name)].Date.values[0]\n",
    "        time = df_date_info[df_date_info.Filename.str.contains(frg_name)].Time.values[0]\n",
    "        datetime = df_date_info[df_date_info.Filename.str.contains(frg_name)].Datetime.values[0]\n",
    "\n",
    "    # check for starting files -- 0 time\n",
    "    if \"_00h_\" in frg_name:\n",
    "        zero_time = True\n",
    "\n",
    "    # get viewpoint\n",
    "    if \"richo\" in file:\n",
    "        # there is some Bricho and some bricho\n",
    "        viewpoint = \"bricho\"\n",
    "    elif \"p_bok\" in file:\n",
    "        viewpoint = \"p-bok\"\n",
    "    elif \"l_bok\" in file:\n",
    "        viewpoint = \"l-bok\"\n",
    "    else:\n",
    "        viewpoint = \"non-specified\"        \n",
    "        \n",
    "    # find the relevant info about which slots to take from the bcg csv\n",
    "    slots = df.loc[df.name.str.contains(bcg_name)].slot.values\n",
    "\n",
    "    # check if there are any results\n",
    "    if slots.size == 0:\n",
    "        # save the name to check later\n",
    "        missing_bcg.append(frg_name)\n",
    "        print(\n",
    "            f\"\\nThe following name was not found in the df.\\nfrg: {frg_name}\\nbcg: {bcg_name}, slots: {slots}\\n\\n\")\n",
    "    else:\n",
    "        if slots.size > 3:\n",
    "            print(\n",
    "                f\"\\nSomething fishy with file {frg_name}\\nbcg: {bcg_name} since there are more than three slots ({slots}).\\n\")\n",
    "\n",
    "        # load the arr\n",
    "        tmp_arr = load_h5_into_np(os.path.join(all_files_path, file))\n",
    "        # loop only over correct shape\n",
    "        if tmp_arr.shape == (1024, 1024):\n",
    "            # go over slots and do the job\n",
    "            for i in slots:\n",
    "                # check if we should check it -- if it is a bad slot\n",
    "                unique_label = file.split(\"_\")[3] + \"_m\" + str(i) + \"_\" + file.split(\"_\")[0] + \"_slot\" + str(i)\n",
    "\n",
    "                if unique_label in bad_slots[\"unique_labels\"].values:\n",
    "                    continue\n",
    "                else:\n",
    "                    # be sure\n",
    "                    area, intensity, full_signal = None, None, None\n",
    "                    y = None\n",
    "\n",
    "                    # load the given slot\n",
    "                    y = tmp_arr[off + (200 * i): off + (200 * (i + 1)), 250:-1]\n",
    "                    # correct for the given slot\n",
    "                    y -= correction_matrix_slots_mice_all[(200 * i): (200 * (i + 1)), :]\n",
    "                    # remove negative values\n",
    "                    y[y < 0] = 0\n",
    "                    #                 plt.imshow(y>background)\n",
    "                    #                 plt.show()\n",
    "                    print(f\"mean {y.mean()} for slot {i} in {file}\")\n",
    "                    #                 bcg_mean_705[j, i] = y.mean()\n",
    "                    signal_arr.append(y.mean())\n",
    "                    #         sns.histplot((y[y>background]).reshape(-1), ax=ax[2*j+1,i])\n",
    "\n",
    "                    # get the measures\n",
    "                    #                 area, intensity, intensity_max = get_total_signal_and_area(y, thr)\n",
    "                    #                 print(f\"area: {area}, intensity: {intensity}, max_int: {intensity_max}\")\n",
    "                    area, intensity, intensity_max, intensity_depo, intensity_med, intensity_med_depo, total_signal, \\\n",
    "                    total_signal_depo, k_ten = get_total_signal_and_area(y, thr)\n",
    "                    print(\n",
    "                        f\"area: {area}, intensity: {intensity}, int_depo: {intensity_depo}, max_int: {intensity_max}, int_med: {intensity_med}, int_med_depo: {intensity_med_depo}\")\n",
    "\n",
    "                    # plot\n",
    "                    if plot_slots:\n",
    "                        temp_arr = None\n",
    "                        temp_arr = y.copy()\n",
    "                        temp_arr[temp_arr < thr] = 0\n",
    "                        plt.figure(figsize=(8, 2))\n",
    "                        sns.heatmap(temp_arr)\n",
    "                        plt.show()\n",
    "                        plt.imshow(temp_arr)\n",
    "                        plt.show()\n",
    "\n",
    "                    # update the dataframe\n",
    "                    df_results = df_results.append({\n",
    "                        \"name\": file,\n",
    "                        \"mouse_name\": '_'.join(frg_name.split('_')[:-3]),\n",
    "                        \"unique_label\": unique_label,\n",
    "                        \"slot\": i,\n",
    "                        \"type\": file.split(\"_\")[3],\n",
    "                        \"viewpoint\": viewpoint,                        \n",
    "                        \"area\": area,\n",
    "                        \"intensity_mean\": intensity,\n",
    "                        \"intensity_mean_depo\": intensity_depo,\n",
    "                        \"intensity_max\": intensity_max,\n",
    "                        \"intensity_median\": intensity_med,\n",
    "                        \"intensity_median_depo\": intensity_med_depo,\n",
    "                        \"full_signal_mean\": y.mean(),\n",
    "                        \"full_signal_sum\": y.sum(),\n",
    "                        \"total_signal\": total_signal,\n",
    "                        \"total_signal_depo\": total_signal_depo,\n",
    "                        \"k10\": k_ten,\n",
    "                        # TODO\n",
    "                        \"date\": date,\n",
    "                        \"time\": time,\n",
    "                        \"datetime\": datetime,\n",
    "                        \"time_zero\": zero_time,\n",
    "                        \"matrix_shape\": 1024\n",
    "                    },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "\n",
    "        # TODO, the issue here is that we need to resize, otherwise corrections don't work\n",
    "        elif tmp_arr.shape == (2048, 2048):\n",
    "            # do interpolation, see below\n",
    "            tmp_arr = cv2.resize(tmp_arr, dsize=reduced_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # go over slots and do the job\n",
    "            for i in slots:\n",
    "                # check if we should check it -- if it is a bad slot\n",
    "                unique_label = file.split(\"_\")[3] + \"_m\" + str(i) + \"_\" + file.split(\"_\")[0] + \"_slot\" + str(i)\n",
    "\n",
    "                if unique_label in bad_slots[\"unique_labels\"].values:\n",
    "                    continue\n",
    "                else:\n",
    "                    # be sure\n",
    "                    area, intensity, full_signal = None, None, None\n",
    "                    y = None\n",
    "\n",
    "                    # load the given slot\n",
    "                    y = tmp_arr[off + (200 * i): off + (200 * (i + 1)), 250:-1]\n",
    "                    # correct for the given slot\n",
    "                    y -= correction_matrix_slots_mice_all[(200 * i): (200 * (i + 1)), :]\n",
    "                    # remove negative values\n",
    "                    y[y < 0] = 0\n",
    "                    #                 plt.imshow(y>background)\n",
    "                    #                 plt.show()\n",
    "                    print(f\"mean {y.mean()} for slot {i} in {file}\")\n",
    "                    #                 bcg_mean_705[j, i] = y.mean()\n",
    "                    signal_arr.append(y.mean())\n",
    "                    #         sns.histplot((y[y>background]).reshape(-1), ax=ax[2*j+1,i])\n",
    "\n",
    "                    # get the measures\n",
    "                    #                 area, intensity, intensity_max = get_total_signal_and_area(y, thr)\n",
    "                    #                 print(f\"area: {area}, intensity: {intensity}, max_int: {intensity_max}\")\n",
    "                    area, intensity, intensity_max, intensity_depo, intensity_med, intensity_med_depo, total_signal, \\\n",
    "                    total_signal_depo, k_ten = get_total_signal_and_area(y, thr)\n",
    "                    print(\n",
    "                        f\"area: {area}, intensity: {intensity}, int_depo: {intensity_depo}, max_int: {intensity_max}, int_med: {intensity_med}, int_med_depo: {intensity_med_depo}\")\n",
    "\n",
    "                    # plot\n",
    "                    if plot_slots:\n",
    "                        temp_arr = None\n",
    "                        temp_arr = y.copy()\n",
    "                        temp_arr[temp_arr < thr] = 0\n",
    "                        plt.figure(figsize=(8, 2))\n",
    "                        sns.heatmap(temp_arr)\n",
    "                        plt.show()\n",
    "                        plt.imshow(temp_arr)\n",
    "                        plt.show()\n",
    "\n",
    "                    # update the dataframe\n",
    "                    df_results = df_results.append({\n",
    "                        \"name\": file,\n",
    "                        \"mouse_name\": '_'.join(frg_name.split('_')[:-3]),\n",
    "                        \"unique_label\": unique_label,\n",
    "                        \"slot\": i,\n",
    "                        \"type\": file.split(\"_\")[3],\n",
    "                        \"viewpoint\": viewpoint,                        \n",
    "                        \"area\": area,\n",
    "                        \"intensity_mean\": intensity,\n",
    "                        \"intensity_mean_depo\": intensity_depo,\n",
    "                        \"intensity_max\": intensity_max,\n",
    "                        \"intensity_median\": intensity_med,\n",
    "                        \"intensity_median_depo\": intensity_med_depo,\n",
    "                        \"full_signal_mean\": y.mean(),\n",
    "                        \"full_signal_sum\": y.sum(),\n",
    "                        \"total_signal\": total_signal,\n",
    "                        \"total_signal_depo\": total_signal_depo,\n",
    "                        \"k10\": k_ten,\n",
    "                        # TODO\n",
    "                        \"date\": date,\n",
    "                        \"time\": time,\n",
    "                        \"datetime\": datetime,\n",
    "                        \"time_zero\": zero_time,\n",
    "                        \"matrix_shape\": 2048\n",
    "                    },\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "        else:\n",
    "            wrong_shape.append(file)\n",
    "\n",
    "# convert flags to bool\n",
    "df_results.time_zero = df_results.time_zero.astype(bool)\n",
    "\n",
    "# convert types\n",
    "df_results = df_results.convert_dtypes()\n",
    "\n",
    "# save\n",
    "df_results.to_csv(\"results_mice.csv\", index=False)   \n",
    "\n",
    "# stop the timer\n",
    "end = timer.time()\n",
    "print(f\"\\n------\\n Processend took {end - start} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Without plotting:\")\n",
    "print(\"Processend took 38.66309714317322 s.\")\n",
    "\n",
    "print(\"With plotting:\")\n",
    "print(f\"Processend took 1167.670970916748 s. ({1167.670970916748/60} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing bcg:\")\n",
    "for x in missing_bcg:\n",
    "    print(x)\n",
    "    \n",
    "print(\"\\nmissing dates:\")\n",
    "for x in missing_date:\n",
    "    print(x)\n",
    "    \n",
    "print(\"\\nvery wrong size (not 1024 nor 2048):\")\n",
    "for x in wrong_shape:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=150 # cutoff\n",
    "print(f\"Mean signal: {np.array(signal_arr).mean()}, std: {np.array(signal_arr).std()}\")\n",
    "print(f\"Max signal: {np.array(signal_arr).max()}, min: {np.array(signal_arr).min()}\")\n",
    "print(f\"Mean with cut off: {np.array(signal_arr)[np.array(signal_arr)>c].mean()} and std: {np.array(signal_arr)[np.array(signal_arr)>c].std()}\")\n",
    "\n",
    "bins = 30\n",
    "sns.histplot(np.array(signal_arr), bins=bins, kde=True, label=\"no cutoff\")\n",
    "sns.histplot(np.array(signal_arr)[np.array(signal_arr)>c], bins=bins, kde=True, color=\"orange\", label=f\"cutoff: {c}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Intensity')\n",
    "plt.title('Distribution of intensities with and without a cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2,figsize=(14,28))\n",
    "sns.scatterplot(x=\"date\", y=\"area\", data=df_results, hue=\"type\", ax=axs[0,0])\n",
    "sns.scatterplot(x=\"date\", y=\"intensity_max\", data=df_results, hue=\"type\", ax=axs[0,1])\n",
    "sns.scatterplot(x=\"date\", y=\"full_signal_mean\", data=df_results, hue=\"type\", ax=axs[1,0])\n",
    "sns.scatterplot(x=\"date\", y=\"full_signal_sum\", data=df_results, hue=\"type\", ax=axs[1,1])\n",
    "sns.scatterplot(x=\"date\", y=\"intensity_mean\", data=df_results, hue=\"type\", ax=axs[2,0])\n",
    "sns.scatterplot(x=\"date\", y=\"intensity_mean_depo\", data=df_results, hue=\"type\", ax=axs[2,1])\n",
    "sns.scatterplot(x=\"date\", y=\"intensity_median\", data=df_results, hue=\"type\", ax=axs[3,0])\n",
    "sns.scatterplot(x=\"date\", y=\"intensity_median_depo\", data=df_results, hue=\"type\", ax=axs[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['area', 'intensity_mean',\n",
    "       'intensity_mean_depo', 'intensity_max', 'intensity_median',\n",
    "       'intensity_median_depo', 'full_signal_mean', 'full_signal_sum',\n",
    "       'total_signal', 'total_signal_depo', 'k10']\n",
    "\n",
    "fig, axs = plt.subplots((len(measures)+1)//2,2,figsize=(14,28))\n",
    "\n",
    "for measure, ax in zip(measures, axs.flatten()):\n",
    "    sns.scatterplot(x=\"date\", y=measure, data=df_results, hue=\"type\", ax=ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "measures = ['area', 'intensity_mean',\n",
    "       'intensity_mean_depo', 'intensity_max', 'intensity_median',\n",
    "       'intensity_median_depo', 'full_signal_mean', 'full_signal_sum',\n",
    "       'total_signal', 'total_signal_depo', 'k10']\n",
    "\n",
    "fig, axs = plt.subplots((len(measures)+1)//2,2,figsize=(14,28))\n",
    "\n",
    "for measure, ax in zip(measures, axs.flatten()):\n",
    "    sns.scatterplot(x=\"date\", y=measure, data=df_results, hue=\"type\", ax=ax)\n",
    "    sns.lineplot(x=\"date\", y=measure, data=df_results, hue=\"type\", ax=ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_type = \"p2\"\n",
    "g = sns.scatterplot(x=\"date\", y=\"intensity_mean_depo\", data=df_results[df_results.type==pol_type], label=pol_type)\n",
    "\n",
    "# g.set_xticklabels(df_results.loc[df_results.type==\"p1\", \"date\"].tolist(), rotation = 90)\n",
    "# g.set_xticklabels(g.get_xticklabels(), rotation = 90)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_type = \"p2\"\n",
    "g = sns.scatterplot(x=\"date\", y=\"k10\", data=df_results[df_results.type==pol_type], label=pol_type)\n",
    "\n",
    "# g.set_xticklabels(df_results.loc[df_results.type==\"p1\", \"date\"].tolist(), rotation = 90)\n",
    "# g.set_xticklabels(g.get_xticklabels(), rotation = 90)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(df_results.corr(), square=True, annot=True)\n",
    "df_results.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix problems in df if there are for some reason some corrupt values for date times\n",
    "\n",
    "# create a series with concat date and time\n",
    "s = pd.to_datetime(df_results[['date','time']].agg(' '.join, axis=1))\n",
    "# add back\n",
    "df_results['datetime'] = pd.to_datetime(df_results['datetime'], errors='coerce').fillna(s)\n",
    "\n",
    "# check\n",
    "print(\"problems with datetime type:\")\n",
    "#https://stackoverflow.com/questions/34207339/how-to-get-all-rows-with-invalid-np-datetime64-dates-in-a-pandas-dataframe\n",
    "df_results.loc[pd.to_datetime(df_results['datetime'], errors='coerce').isnull(), [\"datetime\", \"mouse_name\", \"time\", \"date\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of mice which have been shifted in one day therefore the slot will not be fitting\n",
    "shifted_mice = [\n",
    "    'im75_pondeli_02_i1_polymer_vsechny_bricho_d70_2020-11-16_14-46-49-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im87_pondeli_02_i1_polymer_vsechny_l_bok_d70_2020-11-16_14-51-04-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im111_pondeli_02_i1_polymer_vsechny_p_bok_d70_2020-11-16_14-54-53-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im112_pondeli_02_i1_polymer_vsechny_p_bok_d70_2020-11-16_14-59-39-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im151_pondeli_03_f2_polymer_vsechny_Bricho_d70_2020-11-16_16-17-17-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im164_pondeli_03_f2_polymer_vsechny_l_bok_d70_2020-11-16_16-21-13-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im188_pondeli_03_f2_polymer_vsechny_p_bok_d70_2020-11-16_16-25-01-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im189_pondeli_03_f2_polymer_vsechny_p_bok_d70_2020-11-16_16-28-59-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im227_pondeli_04_p2_polymer_vsechny_Bricho_d70_2020-11-16_19-09-38-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im240_pondeli_04_p2_polymer_vsechny_l_bok_d70_2020-11-16_19-12-59-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im264_pondeli_04_p2_polymer_vsechny_p_bok_d70_2020-11-16_19-16-41-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im265_pondeli_04_p2_polymer_vsechny_p_bok_d70_2020-11-16_19-20-25-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im304_pondeli_05_e1_polymer_vsechny_Bricho_d70_2020-11-16_19-30-32-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im317_pondeli_05_e1_polymer_vsechny_l_bok_d70_2020-11-16_19-34-17-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im341_pondeli_05_e1_polymer_vsechny_p_bok_d70_2020-11-16_19-41-01-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im342_pondeli_05_e1_polymer_vsechny_p_bok_d70_2020-11-16_19-58-29-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im437_streda_13_fyzak_vsechny_p_bok_d70_2020-11-16_20-47-19-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im438_streda_13_fyzak_vsechny_p_bok_d70_2020-11-16_20-51-23-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im115_pondeli_02_i1_polymer_vsechny_p_bok_d85_2020-12-02_11-05-46-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im192_pondeli_03_f2_polymer_vsechny_p_bok_d85_2020-12-02_11-28-13-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im268_pondeli_04_p2_polymer_vsechny_p_bok_d85_2020-12-02_12-11-18-MWL-Ex(750)-Em(830)_Frgrnd.h5',\n",
    "'im345_pondeli_05_e1_polymer_vsechny_p_bok_d85_2020-12-02_14-10-31-MWL-Ex(750)-Em(830)_Frgrnd.h5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it from an external file\n",
    "df_start_time = pd.read_csv(os.path.join(current_path,'seznam_skupin_OG.csv'))\n",
    "df_start_time['datetime'] = pd.to_datetime(df_start_time[['DayAdministered','TimeAdministered']].agg(' '.join, axis=1))\n",
    "\n",
    "# go over all starts\n",
    "for index, row in df_results.iterrows():  \n",
    "    # check \n",
    "    if row[\"name\"] in shifted_mice:\n",
    "        row_slot = row[\"slot\"] +1\n",
    "    else:\n",
    "        row_slot = row[\"slot\"]\n",
    "    \n",
    "    try:\n",
    "        df_results.loc[df_results.index == index, \"start_time2\"] = df_start_time.loc[(df_start_time[\"mouse_name_unique\"] == row[\"mouse_name\"])&(df_start_time[\"Slot\"] == row_slot), \"datetime\"].values[0]# minute\n",
    "    except IndexError:\n",
    "        # if it doesn't have time 0\n",
    "        print(row[\"name\"])\n",
    "    \n",
    "df_results[\"elapsed_time\"] = (df_results[\"datetime\"]-df_results[\"start_time2\"])#.dt.seconds\n",
    "df_results[\"elapsed_time_sec\"] = (df_results[\"datetime\"]-df_results[\"start_time2\"]).dt.total_seconds()\n",
    "\n",
    "\n",
    "# check\n",
    "print(\"This should be empty\")\n",
    "print(df_results[df_results[\"elapsed_time\"].isnull()].mouse_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original way\n",
    "\n",
    "# no_00h_mouse = []\n",
    "# for mouse in df_results.name:\n",
    "#     start_mouse = df_results.loc[df_results[\"name\"]==mouse, \"mouse_name\"].values[0]\n",
    "#     try:\n",
    "#         df_results.loc[df_results[\"name\"]==mouse, \"start_time\"] = df_results.loc[(df_results[\"mouse_name\"]==start_mouse)&(df_results[\"time_zero\"]),\"datetime\"].values[0]# minute\n",
    "#     except IndexError:\n",
    "#         # if it doesn't have time 0\n",
    "#         no_00h_mouse.append(mouse)\n",
    "# #         print(mouse)\n",
    "# print(\"Mice not having 00h source\")\n",
    "# for x in set(no_00h_mouse):\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "# # add elapsed time as a difference\n",
    "# df_results[\"elapsed_time\"] = (df_results[\"datetime\"]-df_results[\"start_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df_results.to_csv(os.path.join(current_path,\"results_mice.csv\"), index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "%watermark -a 'Jan Kadlec' -nmvu -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
